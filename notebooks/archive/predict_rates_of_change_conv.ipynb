{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\marco\\Learning\\pybit-trading-bot\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_WINDOW = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((98270, 64), (98270,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"SOLUSDT-15m-180801.csv\")\n",
    "\n",
    "rate_of_change_1 = ((data[\"close\"] - data[\"open\"]) / data[\"open\"]).to_numpy()[:-127]  # 15 Minutes\n",
    "rate_of_change_4 = ((data[\"close\"].shift(-3) - data[\"open\"]) / data[\"open\"]).to_numpy()[:-127]  # 1 Hour\n",
    "rate_of_change_32 = ((data[\"close\"].shift(-31) - data[\"open\"]) / data[\"open\"]).to_numpy()[:-127]  # 8 Hours\n",
    "rate_of_change_128 = ((data[\"close\"].shift(-127) - data[\"open\"]) / data[\"open\"]).to_numpy()[:-127]  # 1 Day\n",
    "\n",
    "X = rate_of_change_4[:-1]\n",
    "Y = rate_of_change_4[INPUT_WINDOW:]\n",
    "\n",
    "X = np.lib.stride_tricks.sliding_window_view(X, INPUT_WINDOW)\n",
    "\n",
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marco\\AppData\\Local\\Temp\\ipykernel_26604\\2551682548.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X = torch.tensor(X, dtype=torch.float32)\n",
      "C:\\Users\\marco\\AppData\\Local\\Temp\\ipykernel_26604\\2551682548.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  Y = torch.tensor(Y, dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "X = torch.tensor(X, dtype=torch.float32)\n",
    "Y = torch.tensor(Y, dtype=torch.float32)\n",
    "\n",
    "Xtrain = X[:int(len(X) * 0.8)]\n",
    "Ytrain = Y[:int(len(Y) * 0.8)]\n",
    "Xtest = X[int(len(X) * 0.8):]\n",
    "Ytest = Y[int(len(Y) * 0.8):]\n",
    "\n",
    "dataset = TensorDataset(Xtrain, Ytrain)\n",
    "dataloader = DataLoader(dataset, batch_size=256, shuffle=True)\n",
    "\n",
    "\n",
    "class TradingNN(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(TradingNN, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(1, 32, 16)\n",
    "        self.conv2 = nn.Conv1d(32, 64, 16)\n",
    "\n",
    "        self.fc1 = nn.Linear(256, 128)\n",
    "        self.fc2 = nn.Linear(128, 1)\n",
    "\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "        self.pool = nn.AvgPool1d(2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.pool(torch.relu(x))\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.pool(torch.relu(x))\n",
    "\n",
    "        x = x.view(x.shape[0], -1)\n",
    "\n",
    "        x = self.fc1(x)\n",
    "        x = self.dropout(x)\n",
    "        x = torch.relu(x)\n",
    "\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        x = x.squeeze(1)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_semantic_loss(y_pred, y_true):\n",
    "    print(\"Mean scaled absolute error\", torch.mean(torch.abs(y_pred - y_true) / y_true, dim=0))\n",
    "    print(\"Mean absolute error\", torch.mean(torch.abs(y_pred - y_true), dim=0))\n",
    "    print(\"Scaled absolute error\", torch.abs(y_pred - y_true) / y_true)\n",
    "    print(\"First few\", y_pred[:50], y_true[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 308/308 [00:05<00:00, 52.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Loss: 4.296921179047786e-05\n",
      "Test Loss: 0.00010447504610056058\n",
      "Mean scaled absolute error tensor(inf)\n",
      "Mean absolute error tensor(0.0070)\n",
      "Scaled absolute error tensor([-1.0277, -1.0424, -1.2565,  ..., -1.0665, -1.0443, -1.0395])\n",
      "First few tensor([0.0009, 0.0009, 0.0009, 0.0009, 0.0009, 0.0009, 0.0009, 0.0009, 0.0009,\n",
      "        0.0009, 0.0009, 0.0009, 0.0009, 0.0009, 0.0009, 0.0009, 0.0009, 0.0009,\n",
      "        0.0009, 0.0009, 0.0009, 0.0009, 0.0009, 0.0009, 0.0009, 0.0008, 0.0008,\n",
      "        0.0008, 0.0008, 0.0008, 0.0009, 0.0009, 0.0009, 0.0009, 0.0009, 0.0009,\n",
      "        0.0009, 0.0009, 0.0009, 0.0009, 0.0009, 0.0008, 0.0008, 0.0008, 0.0008,\n",
      "        0.0008, 0.0008, 0.0008, 0.0008, 0.0008]) tensor([-0.0313, -0.0206, -0.0034,  0.0041, -0.0040])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 308/308 [00:05<00:00, 53.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss: 0.0001335359556833282\n",
      "Test Loss: 0.0001039196431520395\n",
      "Mean scaled absolute error tensor(inf)\n",
      "Mean absolute error tensor(0.0070)\n",
      "Scaled absolute error tensor([-1.0035, -1.0053, -1.0319,  ..., -1.0082, -1.0054, -1.0048])\n",
      "First few tensor([1.0904e-04, 1.0984e-04, 1.1017e-04, 1.1041e-04, 1.1039e-04, 1.1028e-04,\n",
      "        1.0855e-04, 1.0779e-04, 1.0778e-04, 1.0862e-04, 1.0985e-04, 1.0925e-04,\n",
      "        1.0937e-04, 1.0955e-04, 1.0989e-04, 1.0956e-04, 1.0882e-04, 1.0806e-04,\n",
      "        1.0855e-04, 1.0986e-04, 1.0937e-04, 1.0861e-04, 1.0656e-04, 1.0592e-04,\n",
      "        1.0594e-04, 1.0520e-04, 1.0461e-04, 1.0329e-04, 1.0348e-04, 1.0463e-04,\n",
      "        1.0591e-04, 1.0586e-04, 1.0510e-04, 1.0649e-04, 1.0901e-04, 1.1363e-04,\n",
      "        1.1621e-04, 1.1614e-04, 1.1601e-04, 1.1628e-04, 1.1829e-04, 1.1908e-04,\n",
      "        1.1655e-04, 1.1127e-04, 1.0674e-04, 1.0418e-04, 1.0372e-04, 1.0202e-04,\n",
      "        9.9716e-05, 9.8570e-05]) tensor([-0.0313, -0.0206, -0.0034,  0.0041, -0.0040])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 308/308 [00:05<00:00, 51.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Loss: 0.00012432706716936082\n",
      "Test Loss: 0.00010392539843451232\n",
      "Mean scaled absolute error tensor(inf)\n",
      "Mean absolute error tensor(0.0070)\n",
      "Scaled absolute error tensor([-1.0017, -1.0025, -1.0146,  ..., -1.0040, -1.0027, -1.0023])\n",
      "First few tensor([5.1818e-05, 5.0755e-05, 5.0333e-05, 4.9039e-05, 4.8436e-05, 4.8807e-05,\n",
      "        4.8400e-05, 4.9768e-05, 5.1800e-05, 5.3704e-05, 5.6864e-05, 5.7575e-05,\n",
      "        5.7175e-05, 5.5168e-05, 5.2074e-05, 5.1660e-05, 5.1079e-05, 5.1613e-05,\n",
      "        5.2455e-05, 5.2236e-05, 5.2856e-05, 5.2738e-05, 5.2055e-05, 5.2355e-05,\n",
      "        5.2864e-05, 5.3411e-05, 5.3862e-05, 5.2298e-05, 4.9927e-05, 4.8283e-05,\n",
      "        4.9160e-05, 5.0947e-05, 5.1833e-05, 5.2003e-05, 5.0451e-05, 5.1593e-05,\n",
      "        5.3436e-05, 5.4417e-05, 5.5664e-05, 5.2191e-05, 5.0500e-05, 5.0474e-05,\n",
      "        4.8720e-05, 5.2471e-05, 5.4319e-05, 5.7061e-05, 6.2736e-05, 6.3924e-05,\n",
      "        6.5076e-05, 6.2352e-05]) tensor([-0.0313, -0.0206, -0.0034,  0.0041, -0.0040])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 308/308 [00:06<00:00, 50.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Loss: 0.0001446139212930575\n",
      "Test Loss: 0.00010393888805992901\n",
      "Mean scaled absolute error tensor(inf)\n",
      "Mean absolute error tensor(0.0070)\n",
      "Scaled absolute error tensor([-1.0085, -1.0130, -1.0776,  ..., -1.0201, -1.0134, -1.0120])\n",
      "First few tensor([0.0003, 0.0003, 0.0003, 0.0003, 0.0003, 0.0003, 0.0003, 0.0003, 0.0003,\n",
      "        0.0003, 0.0003, 0.0003, 0.0003, 0.0003, 0.0003, 0.0003, 0.0003, 0.0003,\n",
      "        0.0003, 0.0003, 0.0003, 0.0003, 0.0003, 0.0003, 0.0003, 0.0003, 0.0003,\n",
      "        0.0003, 0.0003, 0.0003, 0.0003, 0.0003, 0.0003, 0.0003, 0.0003, 0.0003,\n",
      "        0.0003, 0.0003, 0.0003, 0.0003, 0.0003, 0.0003, 0.0003, 0.0003, 0.0003,\n",
      "        0.0003, 0.0003, 0.0003, 0.0003, 0.0003]) tensor([-0.0313, -0.0206, -0.0034,  0.0041, -0.0040])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 308/308 [00:05<00:00, 53.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Loss: 8.322076610056683e-05\n",
      "Test Loss: 0.00010392160766059533\n",
      "Mean scaled absolute error tensor(inf)\n",
      "Mean absolute error tensor(0.0070)\n",
      "Scaled absolute error tensor([-1.0026, -1.0040, -1.0240,  ..., -1.0062, -1.0042, -1.0037])\n",
      "First few tensor([8.2488e-05, 8.2575e-05, 8.2678e-05, 8.2596e-05, 8.2856e-05, 8.2988e-05,\n",
      "        8.3187e-05, 8.3342e-05, 8.3427e-05, 8.3576e-05, 8.3588e-05, 8.3638e-05,\n",
      "        8.3382e-05, 8.3188e-05, 8.2950e-05, 8.2802e-05, 8.2703e-05, 8.2498e-05,\n",
      "        8.2547e-05, 8.2508e-05, 8.2785e-05, 8.2845e-05, 8.3136e-05, 8.3354e-05,\n",
      "        8.3189e-05, 8.3093e-05, 8.2496e-05, 8.2242e-05, 8.2062e-05, 8.2095e-05,\n",
      "        8.2460e-05, 8.2421e-05, 8.2549e-05, 8.2559e-05, 8.2421e-05, 8.2631e-05,\n",
      "        8.2793e-05, 8.3059e-05, 8.3334e-05, 8.3302e-05, 8.3442e-05, 8.3446e-05,\n",
      "        8.3477e-05, 8.4020e-05, 8.4200e-05, 8.4483e-05, 8.4495e-05, 8.3911e-05,\n",
      "        8.3660e-05, 8.2847e-05]) tensor([-0.0313, -0.0206, -0.0034,  0.0041, -0.0040])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 308/308 [00:05<00:00, 52.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Loss: 6.674799806205556e-05\n",
      "Test Loss: 0.00010403967462480068\n",
      "Mean scaled absolute error tensor(inf)\n",
      "Mean absolute error tensor(0.0070)\n",
      "Scaled absolute error tensor([-1.0151, -1.0230, -1.1375,  ..., -1.0357, -1.0238, -1.0213])\n",
      "First few tensor([0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005,\n",
      "        0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005,\n",
      "        0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005,\n",
      "        0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005,\n",
      "        0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005,\n",
      "        0.0005, 0.0005, 0.0005, 0.0005, 0.0005]) tensor([-0.0313, -0.0206, -0.0034,  0.0041, -0.0040])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 308/308 [00:05<00:00, 52.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 Loss: 6.808566104155034e-05\n",
      "Test Loss: 0.0001039222624967806\n",
      "Mean scaled absolute error tensor(inf)\n",
      "Mean absolute error tensor(0.0070)\n",
      "Scaled absolute error tensor([-1.0025, -1.0037, -1.0224,  ..., -1.0058, -1.0039, -1.0035])\n",
      "First few tensor([7.7242e-05, 7.7242e-05, 7.7242e-05, 7.7242e-05, 7.7242e-05, 7.7242e-05,\n",
      "        7.7242e-05, 7.7242e-05, 7.7242e-05, 7.7242e-05, 7.7242e-05, 7.7242e-05,\n",
      "        7.7242e-05, 7.7242e-05, 7.7242e-05, 7.7242e-05, 7.7242e-05, 7.7242e-05,\n",
      "        7.7242e-05, 7.7242e-05, 7.7242e-05, 7.7242e-05, 7.7242e-05, 7.7242e-05,\n",
      "        7.7242e-05, 7.7242e-05, 7.7242e-05, 7.7242e-05, 7.7242e-05, 7.7242e-05,\n",
      "        7.7242e-05, 7.7242e-05, 7.7242e-05, 7.7242e-05, 7.7242e-05, 7.7242e-05,\n",
      "        7.7242e-05, 7.7242e-05, 7.7242e-05, 7.7242e-05, 7.7242e-05, 7.7242e-05,\n",
      "        7.7242e-05, 7.7242e-05, 7.7242e-05, 7.7242e-05, 7.7242e-05, 7.7242e-05,\n",
      "        7.7242e-05, 7.7242e-05]) tensor([-0.0313, -0.0206, -0.0034,  0.0041, -0.0040])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 278/308 [00:05<00:00, 50.25it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m     Y_pred \u001b[38;5;241m=\u001b[39m model(X_batch)\n\u001b[0;32m     12\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(Y_pred, Y_batch)\n\u001b[1;32m---> 13\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\marco\\Learning\\pybit-trading-bot\\.venv\\Lib\\site-packages\\torch\\_tensor.py:521\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    512\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    513\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    514\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    519\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    520\u001b[0m     )\n\u001b[1;32m--> 521\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    522\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    523\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\marco\\Learning\\pybit-trading-bot\\.venv\\Lib\\site-packages\\torch\\autograd\\__init__.py:289\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    284\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    286\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    287\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    288\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 289\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    297\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\marco\\Learning\\pybit-trading-bot\\.venv\\Lib\\site-packages\\torch\\autograd\\graph.py:768\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    766\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    767\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 768\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    769\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    770\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    771\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    772\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = TradingNN()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "EPOCHS = 1000\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    for X_batch, Y_batch in tqdm(dataloader):\n",
    "        X_batch = X_batch\n",
    "        optimizer.zero_grad()\n",
    "        Y_pred = model(X_batch)\n",
    "        loss = criterion(Y_pred, Y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    print(f\"Epoch {epoch} Loss: {loss.item()}\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        Y_pred = model(Xtest)\n",
    "        loss = criterion(Y_pred, Ytest)\n",
    "        print(f\"Test Loss: {loss.item()}\")\n",
    "        print_semantic_loss(Y_pred, Ytest)\n",
    "        model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
